from google.colab import drive
drive.mount('/content/drive')

import zipfile as zf
files = zf.ZipFile("/content/drive/MyDrive/FBHM.zip", 'r')
files.extractall('memes')
files.close()

import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
from transformers import LxmertTokenizer, LxmertModel
from PIL import Image
from torchvision import transforms
import json
import os
from tqdm import tqdm
from ultralytics import YOLO
import easyocr

print("Torch version:", torch.__version__)
print("CUDA available:", torch.cuda.is_available())

LxmertModel.from_pretrained("unc-nlp/lxmert-base-uncased")
LxmertTokenizer.from_pretrained("unc-nlp/lxmert-base-uncased")

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

class ToxicMemeDataset(Dataset):
    def __init__(self, json_file, img_dir, tokenizer, max_len, transform=None):
        with open(json_file, "r") as f:
            self.data = json.load(f)
        self.img_dir = img_dir
        self.tokenizer = tokenizer
        self.max_len = max_len
        self.transform = transform

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        item = self.data[idx]
        text = item["text"]
        encoding = self.tokenizer(
            text,
            max_length=self.max_len,
            padding="max_length",
            truncation=True,
            return_tensors="pt",
        )

        img_path = os.path.join(self.img_dir, item["img"])
        image = Image.open(img_path).convert("RGB")
        if self.transform:
            image = self.transform(image)

        label = torch.tensor(item["label"], dtype=torch.long)

        return {
            "input_ids": encoding["input_ids"].squeeze(0),
            "attention_mask": encoding["attention_mask"].squeeze(0),
            "image": image,
            "label": label,
        }

class ToxicMemeClassifier(nn.Module):
    def __init__(self, num_classes=2):
        super(ToxicMemeClassifier, self).__init__()
        self.lxmert = LxmertModel.from_pretrained("unc-nlp/lxmert-base-uncased")
        self.yolo_model = YOLO("yolov8n.pt")
        self.visual_fc = nn.Linear(256, self.lxmert.config.visual_feat_dim)
        self.fc = nn.Linear(self.lxmert.config.hidden_size, num_classes)

    def forward(self, input_ids, attention_mask, images):
        visual_feats_list = []
        for img in images:
            result = self.yolo_model(img.permute(1, 2, 0).cpu().numpy())
            features = result[0].boxes.data.mean(dim=0) if len(result[0].boxes.data) > 0 else torch.zeros(256)
            visual_feats_list.append(features)

        visual_feats = torch.stack(visual_feats_list).to(images.device)
        visual_feats = self.visual_fc(visual_feats).unsqueeze(1)

        batch_size = visual_feats.size(0)
        visual_pos = torch.zeros(batch_size, 1, 4).to(visual_feats.device)

        outputs = self.lxmert(
            input_ids=input_ids,
            attention_mask=attention_mask,
            visual_feats=visual_feats,
            visual_pos=visual_pos,
        )
        logits = self.fc(outputs.pooled_output)
        return logits

def train_model(model, data_loader, optimizer, criterion, device, epochs):
    model = model.to(device)
    for epoch in range(epochs):
        model.train()
        loop = tqdm(data_loader, desc=f"Epoch {epoch + 1}/{epochs}")
        total_loss = 0
        for batch in loop:
            input_ids = batch["input_ids"].to(device)
            attention_mask = batch["attention_mask"].to(device)
            images = batch["image"].to(device)
            labels = batch["label"].to(device)

            outputs = model(input_ids, attention_mask, images)
            loss = criterion(outputs, labels)

            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

            total_loss += loss.item()
            loop.set_postfix(loss=loss.item())
        print(f"Epoch {epoch + 1}: Loss = {total_loss / len(data_loader)}")

def evaluate_model(model, data_loader, device):
    model.eval()
    correct, total = 0, 0
    with torch.no_grad():
        for batch in data_loader:
            input_ids = batch["input_ids"].to(device)
            attention_mask = batch["attention_mask"].to(device)
            images = batch["image"].to(device)
            labels = batch["label"].to(device)

            outputs = model(input_ids, attention_mask, images)
            _, preds = torch.max(outputs, dim=1)

            correct += (preds == labels).sum().item()
            total += labels.size(0)
    print(f"Accuracy: {correct / total:.2f}")

def predict(model, img_path, text, tokenizer, transform, device):
    model = model.to(device)
    encoding = tokenizer(
        text,
        max_length=128,
        padding="max_length",
        truncation=True,
        return_tensors="pt",
    )
    input_ids = encoding["input_ids"].to(device)
    attention_mask = encoding["attention_mask"].to(device)

    image = Image.open(img_path).convert("RGB")
    image = transform(image).unsqueeze(0).to(device)

    with torch.no_grad():
        output = model(input_ids, attention_mask, image)
        _, prediction = torch.max(output, dim=1)
        return prediction.item()

def extract_text_from_image(img_path):
    reader = easyocr.Reader(['en'])
    results = reader.readtext(img_path)
    text = " ".join([result[1] for result in results])
    return text.strip()

if __name__ == "__main__":
    json_file = "/content/123 (1).json"
    img_dir = "/content/memes/FBHM/data/"

    max_len = 128
    batch_size = 16
    learning_rate = 1e-5
    epochs = 5

    tokenizer = LxmertTokenizer.from_pretrained("unc-nlp/lxmert-base-uncased")
    transform = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
    ])

    dataset = ToxicMemeDataset(json_file, img_dir, tokenizer, max_len, transform)
    train_size = int(0.8 * len(dataset))
    test_size = len(dataset) - train_size
    train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])

    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
    test_loader = DataLoader(test_dataset, batch_size=batch_size)

    model = ToxicMemeClassifier(num_classes=2)
    criterion = nn.CrossEntropyLoss()
    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)

    train_model(model, train_loader, optimizer, criterion, device, epochs)
    evaluate_model(model, test_loader, device)

    img_path = "/content/48106.png"
    text = extract_text_from_image(img_path)
    print(f"\nExtracted Text: {text}")

    prediction = predict(model, img_path, text, tokenizer, transform, device)
    print(f"Prediction: {'Toxic' if prediction == 1 else 'Non-toxic'}")
