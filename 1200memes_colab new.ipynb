{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CLcOrNGcg5Py"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9m4KuecXhPF-"
      },
      "outputs": [],
      "source": [
        "import zipfile as zf\n",
        "files = zf.ZipFile(\"/content/memes.zip\", 'r')\n",
        "files.extractall('meme')\n",
        "files.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Ha92t4Chxn-",
        "outputId": "11ddedd4-9102-4ba3-bc8f-741c741fd2c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting easyocr\n",
            "  Downloading easyocr-1.7.2-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from easyocr) (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.5 in /usr/local/lib/python3.11/dist-packages (from easyocr) (0.20.1+cu121)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.11/dist-packages (from easyocr) (4.10.0.84)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from easyocr) (1.13.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from easyocr) (1.26.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from easyocr) (11.1.0)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.11/dist-packages (from easyocr) (0.25.0)\n",
            "Collecting python-bidi (from easyocr)\n",
            "  Downloading python_bidi-0.6.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from easyocr) (6.0.2)\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.11/dist-packages (from easyocr) (2.0.6)\n",
            "Collecting pyclipper (from easyocr)\n",
            "  Downloading pyclipper-1.3.0.post6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.0 kB)\n",
            "Collecting ninja (from easyocr)\n",
            "  Downloading ninja-1.11.1.3-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (5.3 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->easyocr) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch->easyocr) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->easyocr) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->easyocr) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->easyocr) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch->easyocr) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch->easyocr) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch->easyocr) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->easyocr) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch->easyocr) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch->easyocr) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch->easyocr) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch->easyocr) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch->easyocr) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->easyocr) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch->easyocr) (12.1.105)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch->easyocr) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->easyocr) (1.13.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->easyocr) (12.6.85)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->easyocr) (1.3.0)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image->easyocr) (2.36.1)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image->easyocr) (2024.12.12)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.11/dist-packages (from scikit-image->easyocr) (24.2)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image->easyocr) (0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->easyocr) (3.0.2)\n",
            "Downloading easyocr-1.7.2-py3-none-any.whl (2.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m63.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ninja-1.11.1.3-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (422 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m422.9/422.9 kB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyclipper-1.3.0.post6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (969 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m969.6/969.6 kB\u001b[0m \u001b[31m50.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_bidi-0.6.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (286 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m286.6/286.6 kB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: python-bidi, pyclipper, ninja, easyocr\n",
            "Successfully installed easyocr-1.7.2 ninja-1.11.1.3 pyclipper-1.3.0.post6 python-bidi-0.6.3\n"
          ]
        }
      ],
      "source": [
        "pip install easyocr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fKqZ73P9h7hF",
        "outputId": "eb36b61e-379a-4b24-bb37-60cec45ba590"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              image                                     extracted_text  \\\n",
            "0    520_NM_pic.jpg  IGdevilmemez_81७ cooamdep0 २s८l Ic०$ Monkeys क...   \n",
            "1  151_M_pic_10.jpg  philmyyy We're both dead, but if we're born ag...   \n",
            "2     43_NM_pic.jpg  When my Bestfriend doesn t tie a Friendship ba...   \n",
            "3    514_NM_pic.jpg  *Someone :- Tum apne doston ko kis naam se bul...   \n",
            "4   506_M_pic_2.jpg  १४ Y Ola Nibbi After Sex eleosturk Aaj Usne Mu...   \n",
            "\n",
            "  toxicity_label  toxicity_score  \n",
            "0          Toxic        0.372312  \n",
            "1          Toxic        0.294317  \n",
            "2          Toxic        0.311084  \n",
            "3          Toxic        0.308909  \n",
            "4          Toxic        0.297873  \n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import CLIPProcessor, CLIPModel\n",
        "from PIL import Image\n",
        "import os\n",
        "import pandas as pd\n",
        "import easyocr\n",
        "import cv2\n",
        "\n",
        "# Initialize EasyOCR Reader for English, Hindi, and Marathi\n",
        "reader = easyocr.Reader(['en', 'hi'], gpu=True)\n",
        "\n",
        "# Initialize the CLIP model and processor\n",
        "model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
        "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
        "\n",
        "# Define the meme image directory\n",
        "meme_directory = \"/content/meme/memes\"\n",
        "\n",
        "# Function to classify toxicity based on image and text\n",
        "def classify_toxicity(image_path, text):\n",
        "    image = Image.open(image_path)\n",
        "    inputs = processor(\n",
        "        text=[text],\n",
        "        images=image,\n",
        "        return_tensors=\"pt\",\n",
        "        padding=True,\n",
        "        truncation=True\n",
        "    )\n",
        "    outputs = model(**inputs)\n",
        "    image_features = outputs.image_embeds\n",
        "    text_features = outputs.text_embeds\n",
        "    similarity = torch.cosine_similarity(image_features, text_features)\n",
        "    toxicity_threshold = 0.2\n",
        "    label = \"Toxic\" if similarity > toxicity_threshold else \"Non-toxic\"\n",
        "    return label, similarity.item()\n",
        "\n",
        "# Function to extract text from image using EasyOCR\n",
        "def extract_text_from_image(image_path):\n",
        "    result = reader.readtext(image_path, detail=1)\n",
        "    extracted_text = \" \".join([entry[1] for entry in result])\n",
        "    return extracted_text.strip()\n",
        "\n",
        "# Process all meme images in the directory\n",
        "results = []\n",
        "for filename in os.listdir(meme_directory):\n",
        "    if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
        "        image_path = os.path.join(meme_directory, filename)\n",
        "        text = extract_text_from_image(image_path)\n",
        "        if not text:\n",
        "            continue\n",
        "        label, score = classify_toxicity(image_path, text)\n",
        "        results.append({\n",
        "            \"image\": filename,\n",
        "            \"extracted_text\": text,\n",
        "            \"toxicity_label\": label,\n",
        "            \"toxicity_score\": score\n",
        "        })\n",
        "\n",
        "# Convert results into a DataFrame and save to CSV\n",
        "df = pd.DataFrame(results)\n",
        "df.to_csv(\"/content/meme/memes/meme_toxicity_results.csv\", index=False)\n",
        "print(df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fSFFs6LKDH4I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "752f7136-0d1b-41a7-9aad-b1c38651f59c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5, Loss: 0.14073807795842488\n",
            "Epoch 2/5, Loss: 0.07566362790763378\n",
            "Epoch 3/5, Loss: 0.05720887634903193\n",
            "Epoch 4/5, Loss: 0.0510748348881801\n",
            "Epoch 5/5, Loss: 0.040846751412997644\n",
            "✅ Model saved at: /content/meme/meme_toxicity_classifier.pth\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import CLIPProcessor, CLIPModel\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "clip_model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
        "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
        "CSV_FILE = \"/content/meme/memes/meme_toxicity_results.csv\"\n",
        "IMAGE_DIR = \"/content/meme/memes\"\n",
        "\n",
        "\n",
        "class MemeDataset(Dataset):\n",
        "    def __init__(self, csv_file, image_dir, processor):\n",
        "        self.data = pd.read_csv(csv_file)\n",
        "        self.image_dir = image_dir\n",
        "        self.processor = processor\n",
        "        self.label_map = {\"Non-toxic\": 0, \"Toxic\": 1}\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.data.iloc[idx]\n",
        "        image_path = os.path.join(self.image_dir, row[\"image\"])\n",
        "        text = row[\"extracted_text\"]\n",
        "        label = self.label_map[row[\"toxicity_label\"]]\n",
        "\n",
        "        # Load image\n",
        "        image = Image.open(image_path).convert(\"RGB\")\n",
        "\n",
        "        return image, text, label\n",
        "\n",
        "def collate_fn(batch):\n",
        "    images, texts, labels = zip(*batch)\n",
        "    inputs = processor(text=list(texts), images=list(images), return_tensors=\"pt\", padding=True, truncation=True)\n",
        "    labels = torch.tensor(labels, dtype=torch.long)  # Convert labels to tensor\n",
        "    return inputs, labels\n",
        "\n",
        "dataset = MemeDataset(CSV_FILE, IMAGE_DIR, processor)\n",
        "dataloader = DataLoader(dataset, batch_size=8, shuffle=True, collate_fn=collate_fn)\n",
        "\n",
        "class ToxicityClassifier(nn.Module):\n",
        "    def __init__(self, clip_model):\n",
        "        super(ToxicityClassifier, self).__init__()\n",
        "        self.clip = clip_model\n",
        "        self.fc = nn.Linear(512, 2)  # 512 is CLIP embedding size\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        outputs = self.clip(**inputs)\n",
        "        features = outputs.image_embeds + outputs.text_embeds  # Fuse image & text features\n",
        "        logits = self.fc(features)\n",
        "        return logits\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = ToxicityClassifier(clip_model).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "EPOCHS = 5\n",
        "for epoch in range(EPOCHS):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for batch_inputs, batch_labels in dataloader:\n",
        "        batch_inputs = {key: val.to(device) for key, val in batch_inputs.items()}\n",
        "        batch_labels = batch_labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(batch_inputs)\n",
        "        loss = criterion(outputs, batch_labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{EPOCHS}, Loss: {total_loss / len(dataloader)}\")\n",
        "\n",
        "MODEL_PATH = \"/content/meme/meme_toxicity_classifier.pth\"\n",
        "torch.save(model.state_dict(), MODEL_PATH)\n",
        "print(f\"Model saved at: {MODEL_PATH}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model.load_state_dict(torch.load(MODEL_PATH, map_location=device))\n",
        "model = model.to(device)\n",
        "model.eval()\n",
        "\n",
        "def predict_toxicity(image_path, text, model, processor):\n",
        "    image = Image.open(image_path).convert(\"RGB\")\n",
        "    inputs = processor(text=[text], images=image, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "    inputs = {key: val.to(device) for key, val in inputs.items()}\n",
        "\n",
        "    with torch.no_grad():\n",
        "        logits = model(inputs)\n",
        "        prediction = torch.argmax(logits, dim=1).item()\n",
        "\n",
        "    return \"Toxic\" if prediction == 1 else \"Non-toxic\"\n",
        "\n",
        "test_image = \"/content/19_M_pic_23.jpg\"\n",
        "# test_text = \" meme text\"\n",
        "# result = predict_toxicity(test_image, test_text, model, processor)\n",
        "# print(test_text)\n",
        "# print(\"Prediction:\", result)\n",
        "\n",
        "test_text = extract_text_from_image(test_image)\n",
        "\n",
        "# ✅ Now predict toxicity using real extracted text\n",
        "result = predict_toxicity(test_image, test_text, model, processor)\n",
        "\n",
        "print(\"Extracted Text:\", test_text)\n",
        "print(\"Prediction:\", result)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ScdCsqYUIo0m",
        "outputId": "4512957c-2c74-4fc0-b2b4-64f1f17e5750"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-17-06ceeca24530>:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(MODEL_PATH, map_location=device))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted Text: गधे की तो जिंदगी बन गई रे बाबा\n",
            "Prediction: Toxic\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import CLIPProcessor, CLIPModel\n",
        "from PIL import Image\n",
        "import os\n",
        "import pandas as pd\n",
        "import easyocr\n",
        "import re\n",
        "\n",
        "\n",
        "reader = easyocr.Reader(['en','hi'])\n",
        "\n",
        "\n",
        "model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
        "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
        "\n",
        "\n",
        "meme_directory = \"/content/meme/memes\"\n",
        "\n",
        "\n",
        "def preprocess_text(text):\n",
        "\n",
        "    text = re.sub(r'\\S+@\\S+\\.\\S+', '', text)\n",
        "\n",
        "    text = re.sub(r'http\\S+|www\\S+', '', text)\n",
        "\n",
        "    text = re.sub(r'[^A-Za-z\\s]', '', text)\n",
        "\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    return text\n",
        "\n",
        "\n",
        "def classify_toxicity(image_path, text):\n",
        "\n",
        "    image = Image.open(image_path)\n",
        "\n",
        "\n",
        "    inputs = processor(\n",
        "        text=[text],\n",
        "        images=image,\n",
        "        return_tensors=\"pt\",\n",
        "        padding=True,\n",
        "        truncation=True\n",
        "    )\n",
        "\n",
        "\n",
        "    outputs = model(**inputs)\n",
        "\n",
        "\n",
        "    image_features = outputs.image_embeds\n",
        "    text_features = outputs.text_embeds\n",
        "\n",
        "    similarity = torch.cosine_similarity(image_features, text_features)\n",
        "    toxicity_threshold = 0.4\n",
        "    label = \"Toxic\" if similarity > toxicity_threshold else \"Non-toxic\"\n",
        "    return label, similarity.item()\n",
        "\n",
        "def extract_text_from_image(image_path):\n",
        "\n",
        "    result = reader.readtext(image_path)\n",
        "\n",
        "    text = \" \".join([entry[1] for entry in result])\n",
        "\n",
        "    text = preprocess_text(text)\n",
        "    return text.strip()\n",
        "\n",
        "\n",
        "results = []\n",
        "for filename in os.listdir(meme_directory):\n",
        "    if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
        "        image_path = os.path.join(meme_directory, filename)\n",
        "\n",
        "        text = extract_text_from_image(image_path)\n",
        "        if not text:\n",
        "            continue\n",
        "\n",
        "        label, score = classify_toxicity(image_path, text)\n",
        "\n",
        "        results.append({\n",
        "            \"image\": filename,\n",
        "            \"extracted_text\": text,\n",
        "            \"toxicity_label\": label,\n",
        "            \"toxicity_score\": score\n",
        "        })\n",
        "\n",
        "df = pd.DataFrame(results)\n",
        "\n",
        "df.to_csv(\"meme_toxicity_results_new1.csv\", index=False)\n",
        "\n",
        "print(df.head())"
      ],
      "metadata": {
        "id": "jhY671sAKdve",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3605dad-be2f-4197-ef61-9bc516000780"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:easyocr.easyocr:Downloading recognition model, please wait. This may take several minutes depending upon your network connection.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Progress: |██████████████████████████████████████████████████| 100.0% Complete              image                                     extracted_text  \\\n",
            "0    520_NM_pic.jpg        IGdevilmemez cooamdep sl Ic Monkeys Ooooaos   \n",
            "1  151_M_pic_10.jpg  philmyyy Were both dead but if were born again...   \n",
            "2     43_NM_pic.jpg  When my Bestfriend doesn t tie a Friendship ba...   \n",
            "3    514_NM_pic.jpg  Someone Tum apne doston ko kis naam se bulate ...   \n",
            "4   506_M_pic_2.jpg  Y Ola Nibbi After Sex eleosturk Aaj Usne Muje ...   \n",
            "\n",
            "  toxicity_label  toxicity_score  \n",
            "0          Toxic        0.301375  \n",
            "1          Toxic        0.273048  \n",
            "2          Toxic        0.325062  \n",
            "3          Toxic        0.286841  \n",
            "4          Toxic        0.291741  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Zf3E56g7_NH-"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}