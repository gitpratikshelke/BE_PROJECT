{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "WrC0KA9IID4R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile as zf\n",
        "files = zf.ZipFile(\"/content/drive/MyDrive/BE Project/FBHM.zip\", 'r')\n",
        "files.extractall('memes')\n",
        "files.close()"
      ],
      "metadata": {
        "id": "u5UqcnNhIGNV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install transformers torch torchvision tqdm\n",
        "pip install torch"
      ],
      "metadata": {
        "id": "dw3XMY6tIJ3h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "print(\"Torch version:\", torch.__version__)\n",
        "print(\"Torchvision version:\", torchvision.__version__)\n",
        "print(\"CUDA available:\", torch.cuda.is_available())"
      ],
      "metadata": {
        "id": "inTJQZviIWMC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade transformers"
      ],
      "metadata": {
        "id": "bkPLu3knIdgc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import LxmertModel, LxmertTokenizer\n",
        "LxmertModel.from_pretrained(\"unc-nlp/lxmert-base-uncased\")\n",
        "LxmertTokenizer.from_pretrained(\"unc-nlp/lxmert-base-uncased\")"
      ],
      "metadata": {
        "id": "NYKk9MfKIgAv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import LxmertTokenizer, LxmertModel\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "import json\n",
        "import os\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "mZ9Q7vONIiHb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "I3cFbl9eIkii"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Main Script\n",
        "if __name__ == \"__main__\":\n",
        "    # Paths\n",
        "    json_file = \"/content/dataset22.json\"\n",
        "    img_dir = \"/content/memes/FBHM/data/img\"\n",
        "\n",
        "    # Hyperparameters\n",
        "    max_len = 128\n",
        "    batch_size = 16\n",
        "    learning_rate = 1e-5\n",
        "    epochs = 5\n",
        "\n",
        "    # Tokenizer and Transform\n",
        "    tokenizer = LxmertTokenizer.from_pretrained(\"unc-nlp/lxmert-base-uncased\")\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "    ])\n",
        "\n",
        "    # Dataset and DataLoader\n",
        "    dataset = ToxicMemeDataset(json_file, img_dir, tokenizer, max_len, transform)\n",
        "    train_size = int(0.8 * len(dataset))\n",
        "    test_size = len(dataset) - train_size\n",
        "    train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
        "\n",
        "    # Model, Loss, Optimizer\n",
        "    model = ToxicMemeClassifier(num_classes=2)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    # Train and Evaluate\n",
        "    train_model(model, train_loader, optimizer, criterion, device, epochs)\n",
        "    evaluate_model(model, test_loader, device)"
      ],
      "metadata": {
        "id": "ThYlwAKELAwO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Dataset Loading\n",
        "class ToxicMemeDataset(Dataset):\n",
        "    def __init__(self, json_file, img_dir, tokenizer, max_len, transform=None):\n",
        "        with open(json_file, \"r\") as f:\n",
        "            self.data = json.load(f)\n",
        "        self.img_dir = img_dir\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = self.data[idx]\n",
        "\n",
        "        text = item[\"text\"]\n",
        "        encoding = self.tokenizer(\n",
        "            text,\n",
        "            max_length=self.max_len,\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "            return_tensors=\"pt\",\n",
        "        )\n",
        "\n",
        "        img_path = os.path.join(self.img_dir, item[\"img\"])\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        label = torch.tensor(item[\"label\"], dtype=torch.long)\n",
        "\n",
        "        return {\n",
        "            \"input_ids\": encoding[\"input_ids\"].squeeze(0),\n",
        "            \"attention_mask\": encoding[\"attention_mask\"].squeeze(0),\n",
        "            \"image\": image,\n",
        "            \"label\": label,\n",
        "        }"
      ],
      "metadata": {
        "id": "3s6Odtq4IlNl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Model Definition - Model Architecture\n",
        "class ToxicMemeClassifier(nn.Module):\n",
        "    def __init__(self, num_classes=2):\n",
        "        super(ToxicMemeClassifier, self).__init__()\n",
        "        self.lxmert = LxmertModel.from_pretrained(\"unc-nlp/lxmert-base-uncased\")\n",
        "\n",
        "        resnet = models.resnet50(pretrained=True)\n",
        "        self.cnn_backbone = nn.Sequential(*list(resnet.children())[:-1])\n",
        "        self.visual_fc = nn.Linear(resnet.fc.in_features, self.lxmert.config.visual_feat_dim)\n",
        "\n",
        "\n",
        "        self.fc = nn.Linear(self.lxmert.config.hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, images):\n",
        "        visual_feats = self.cnn_backbone(images).squeeze(-1).squeeze(-1)\n",
        "        visual_feats = self.visual_fc(visual_feats).unsqueeze(1)\n",
        "\n",
        "        batch_size = visual_feats.size(0)\n",
        "        visual_pos = torch.zeros(batch_size, 1, 4).to(visual_feats.device)  # One region per image\n",
        "\n",
        "        outputs = self.lxmert(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            visual_feats=visual_feats,\n",
        "            visual_pos=visual_pos,\n",
        "        )\n",
        "        logits = self.fc(outputs.pooled_output)\n",
        "        return logits\n"
      ],
      "metadata": {
        "id": "kir88J6bIval"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Training Function\n",
        "def train_model(model, data_loader, optimizer, criterion, device, epochs):\n",
        "    model = model.to(device)\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        loop = tqdm(data_loader, desc=f\"Epoch {epoch + 1}/{epochs}\")\n",
        "        total_loss = 0\n",
        "        for batch in loop:\n",
        "            input_ids = batch[\"input_ids\"].to(device)\n",
        "            attention_mask = batch[\"attention_mask\"].to(device)\n",
        "            images = batch[\"image\"].to(device)\n",
        "            labels = batch[\"label\"].to(device)\n",
        "\n",
        "\n",
        "            outputs = model(input_ids, attention_mask, images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            loop.set_postfix(loss=loss.item())\n",
        "        print(f\"Epoch {epoch + 1}: Loss = {total_loss / len(data_loader)}\")"
      ],
      "metadata": {
        "id": "gMgMbeM1I208"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation Function\n",
        "def evaluate_model(model, data_loader, device):\n",
        "    model.eval()\n",
        "    correct, total = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for batch in data_loader:\n",
        "            input_ids = batch[\"input_ids\"].to(device)\n",
        "            attention_mask = batch[\"attention_mask\"].to(device)\n",
        "            images = batch[\"image\"].to(device)\n",
        "            labels = batch[\"label\"].to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask, images)\n",
        "            _, preds = torch.max(outputs, dim=1)\n",
        "\n",
        "            correct += (preds == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "    print(f\"Accuracy: {correct / total:.2f}\")"
      ],
      "metadata": {
        "id": "CwUsP-o_JnrT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_model(model, data_loader, device):\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in data_loader:\n",
        "            input_ids = batch[\"input_ids\"].to(device)\n",
        "            attention_mask = batch[\"attention_mask\"].to(device)\n",
        "            images = batch[\"image\"].to(device)\n",
        "            labels = batch[\"label\"].to(device)\n",
        "\n",
        "            # Get model predictions\n",
        "            outputs = model(input_ids, attention_mask, images)\n",
        "            _, preds = torch.max(outputs, dim=1)\n",
        "\n",
        "            correct += (preds == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    # Calculate accuracy\n",
        "    accuracy = correct / total\n",
        "    print(f\"Test Accuracy: {accuracy:.2f}\")\n",
        "\n",
        "    return all_preds, all_labels"
      ],
      "metadata": {
        "id": "VwklQZmXK1LO"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the model on the test dataset\n",
        "test_preds, test_labels = test_model(model, test_loader, device)"
      ],
      "metadata": {
        "id": "IwqFHoyMLTTD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), \"toxic_meme_classifier.pth\")"
      ],
      "metadata": {
        "id": "Zjuj1lFOLhY8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(model, img_path, text, tokenizer, transform, device):\n",
        "    model = model.to(device)\n",
        "    # Process text\n",
        "    encoding = tokenizer(\n",
        "        text,\n",
        "        max_length=128,\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        return_tensors=\"pt\",\n",
        "    )\n",
        "    input_ids = encoding[\"input_ids\"].to(device)\n",
        "    attention_mask = encoding[\"attention_mask\"].to(device)\n",
        "\n",
        "    # Process image\n",
        "    image = Image.open(img_path).convert(\"RGB\")\n",
        "    image = transform(image).unsqueeze(0).to(device)\n",
        "\n",
        "    # Model inference\n",
        "    with torch.no_grad():\n",
        "        output = model(input_ids, attention_mask, image)\n",
        "        _, prediction = torch.max(output, dim=1)\n",
        "        return prediction.item()\n"
      ],
      "metadata": {
        "id": "2DzyJpE3MVCH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install easyocr"
      ],
      "metadata": {
        "id": "FP2wqwIcMfjN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import easyocr\n",
        "from PIL import Image\n",
        "\n",
        "def extract_text_from_image(img_path):\n",
        "    # Initialize the EasyOCR reader for English\n",
        "    reader = easyocr.Reader(['en'])\n",
        "\n",
        "    # Use EasyOCR to extract text from the image\n",
        "    results = reader.readtext(img_path)\n",
        "\n",
        "    # Combine all extracted text (if any)\n",
        "    text = \" \".join([result[1] for result in results])\n",
        "\n",
        "    return text.strip()\n",
        "\n",
        "# Example usage\n",
        "img_path = \"/content/bomb.png\"\n",
        "# text = extract_text_from_image(img_path)\n",
        "\n",
        "text = \"jesus\"\n",
        "print(f\"\\n Extracted Text: {text}\")\n",
        "\n",
        "# Now predict using the model\n",
        "prediction = predict(model, img_path, text, tokenizer, transform, device)\n",
        "print(f\"Prediction: {'Toxic' if prediction == 1 else 'Non-toxic'}\")\n"
      ],
      "metadata": {
        "id": "5yZJKTOFMg-y"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}